{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 772)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread('Data Set\\Answer Scripts\\Answer Scripts\\A\\JJ502.jpg', cv.IMREAD_GRAYSCALE)\n",
    "assert img is not None\n",
    "\n",
    "scale_percent_w= 25  # Percentage of the original size width\n",
    "scale_percent_h= 30  # Percentage of the original size height\n",
    "width = int(img.shape[1] * scale_percent_w / 100)\n",
    "height = int(img.shape[0] * scale_percent_h/ 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# Resize image\n",
    "resized_image = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
    "\n",
    "# size of the image\n",
    "print(resized_image.shape)\n",
    "\n",
    "imshow = cv.imshow('Image', resized_image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the  area of interest\n",
    "x, y, w, h = 10, 180, 550, 350\n",
    "roi = resized_image[y:y+h, x:x+w]\n",
    "\n",
    "# Display the extracted region\n",
    "cv.imshow('ROI', roi)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 3, 1, 4, 1, 4, 4, 2, 3, 1, 1, 4, 4, 1, 1, 3, 2, 1, 4, 1, 5, 2, 3, 5, 1, 2, 3, 3, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_student_answers(image_path):\n",
    "    #img = image_path\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize the image if it's too large (optional step)\n",
    "    height, width = img.shape\n",
    "    if height > 1000:\n",
    "        img = cv2.resize(img, (width // 2, height // 2))\n",
    "    \n",
    "    # Apply Gaussian blur to smooth the image (helpful for better circle detection)\n",
    "    blurred = cv2.GaussianBlur(img, (9, 9), 2.2)\n",
    "\n",
    "    # Apply Hough Circle Transform to detect circles (bubbles)\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30,\n",
    "                               param1=50, param2=30, minRadius=9, maxRadius=19)\n",
    "\n",
    "    # If no circles are found, return an empty list\n",
    "    if circles is None:\n",
    "        print(\"No bubbles found!\")\n",
    "        return []\n",
    "\n",
    "    # Convert circle coordinates to integers\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "\n",
    "    # Visualize the detected circles on the image for debugging\n",
    "    output = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for (x, y, r) in circles:\n",
    "        cv2.circle(output, (x, y), r, (0, 255, 0), 2)\n",
    "\n",
    "    # Show the image with detected bubbles\n",
    "    cv2.imshow(\"Detected Bubbles\", output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Sort the circles by their y-coordinate, and then x-coordinate (top-to-bottom, left-to-right)\n",
    "    circles = sorted(circles, key=lambda c: (c[1], c[0]))\n",
    "\n",
    "    # Define the number of questions and number of choices per question\n",
    "    num_questions = 50\n",
    "    num_choices = 5  # Assuming 5 choices per question (1-5)\n",
    "\n",
    "    # Initialize a list to store detected answers\n",
    "    student_answers = []\n",
    "\n",
    "    # Group circles into batches of 5 (one batch per question)\n",
    "    for q in range(num_questions):\n",
    "        question_bubbles = circles[q * num_choices:(q + 1) * num_choices]\n",
    "        \n",
    "        # Sort the bubbles horizontally to map them to the correct answer options (1-5)\n",
    "        question_bubbles = sorted(question_bubbles, key=lambda c: c[0])  # Sort left-to-right\n",
    "\n",
    "        filled_option = None\n",
    "        max_intensity = 0\n",
    "        \n",
    "        # Check which bubble is filled (darkest bubble)\n",
    "        for idx, (x, y, r) in enumerate(question_bubbles):\n",
    "            # Create a circular mask to isolate the bubble\n",
    "            mask = np.zeros(img.shape, dtype=\"uint8\")\n",
    "            cv2.circle(mask, (x, y), r, 255, -1)\n",
    "\n",
    "            # Use the mask to count the non-zero pixels inside the bubble\n",
    "            bubble_intensity = cv2.mean(img, mask=mask)[0]\n",
    "\n",
    "            # Assume the darkest bubble is the filled one (least intensity value)\n",
    "            if bubble_intensity < max_intensity or filled_option is None:\n",
    "                max_intensity = bubble_intensity\n",
    "                filled_option = idx + 1  # Option is 1-indexed\n",
    "\n",
    "        # Append the detected answer to the list\n",
    "        student_answers.append(filled_option)\n",
    "\n",
    "    return student_answers\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'Data Set\\Answer Scripts\\Answer Scripts\\A\\JJ502.jpg'\n",
    "#image_path = roi\n",
    "student_answers = extract_student_answers(image_path)\n",
    "print(student_answers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
